{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KktmNyJ5nTBb"
   },
   "source": [
    "# Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from utils.lemmatization import Lemmatization\n",
    "from utils.preprocessing import Utilities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "movies = pd.read_csv('input/tmdb_5000_movies.csv')\n",
    "\n",
    "print(len(movies))\n",
    "# remove movies where overview is null or equals to ''\n",
    "movies = movies.dropna(axis=0, subset=['overview'])\n",
    "\n",
    "movies = movies[movies['overview'] != '']\n",
    "print(len(movies))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot observations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Tokenize each paragraph in the 'overview' column and calculate the number of tokens\n",
    "movies['tokens'] = movies['overview'].apply(lambda x: len(word_tokenize(x)))\n",
    "\n",
    "\n",
    "# Calculate min, max, and average number of tokens\n",
    "min_tokens = movies['tokens'].min()\n",
    "max_tokens = movies['tokens'].max()\n",
    "avg_tokens = movies['tokens'].mean()\n",
    "\n",
    "print(f\"Minimum number of tokens: {min_tokens}\")\n",
    "print(f\"Maximum number of tokens: {max_tokens}\")\n",
    "print(f\"Average number of tokens: {avg_tokens}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# remove movies where tokens are 0\n",
    "movies = movies[movies['tokens'] != 0]\n",
    "\n",
    "# Calculate min, max, and average number of tokens\n",
    "min_tokens = movies['tokens'].min()\n",
    "max_tokens = movies['tokens'].max()\n",
    "avg_tokens = movies['tokens'].mean()\n",
    "\n",
    "print(f\"Minimum number of tokens: {min_tokens}\")\n",
    "print(f\"Maximum number of tokens: {max_tokens}\")\n",
    "print(f\"Average number of tokens: {avg_tokens}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "movies.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "movies.iloc[0]['overview']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove stop words and punctuation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "movies['processed_plot'] = movies['overview'].apply(Utilities.preprocess)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print plots before and after preprocessing for the first 5 movies."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "display(movies[['overview', 'processed_plot']].head(5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lemmatization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "movies['lem_processed_plot'] = movies['processed_plot'].apply(Lemmatization.lemmatize_sent)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "display(movies[['processed_plot', 'lem_processed_plot']].head(5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "def calculate_similarity(df):\n",
    "  overview_df = df['lem_processed_plot']\n",
    "  movies_vector_1 = vectorizer.fit_transform(overview_df)\n",
    "\n",
    "  return cosine_similarity(movies_vector_1)\n",
    "\n",
    "\n",
    "similarity_matrix = calculate_similarity(movies)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def get_top_n_similar_indices(similarity_matrix, n=10):\n",
    "    top_n_similar_indices = {}\n",
    "\n",
    "    for i in range(similarity_matrix.shape[0]):\n",
    "        similarity_scores = similarity_matrix[i]\n",
    "        top_indices = np.argsort(similarity_scores)[::-1][1:n+1]\n",
    "        top_n_similar_indices[i] = top_indices\n",
    "\n",
    "    return top_n_similar_indices\n",
    "\n",
    "movies['similar_movie_indices'] = get_top_n_similar_indices(similarity_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "movies.iloc[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Categorize reviews"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('input/reviews.csv')\n",
    "\n",
    "reviews.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset info"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see if the positive and negative reviews are equally distributed within the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt = reviews['sentiment'].value_counts().plot.pie(autopct='%1.1f%%',\n",
    "                                                   colors=sns.palettes.mpl_palette('Dark2'),\n",
    "                                                   labels=None,\n",
    "                                                   legend=True,\n",
    "                                                   startangle=90)\n",
    "plt.legend(title=\"Sentiment\", labels=reviews['sentiment'].value_counts().index)\n",
    "# plt.bar_label(plt.containers[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt = reviews['sentiment'].value_counts().plot.barh(color=sns.palettes.mpl_palette('Dark2'))\n",
    "\n",
    "plt.bar_label(plt.containers[0])\n",
    "\n",
    "plt.set_xlim(right=29000)  # adjust xlim to fit labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see they are equally distributed in our dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocess"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since many reviews contain html tags, we are also going to remove them too"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reviews['processed_review'] = reviews['review'].apply(Utilities.remove_html)\n",
    "\n",
    "display(reviews[['review', 'processed_review']].head(5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Use the preprocess method that was used in the movies plot\n",
    "\n",
    "reviews['processed_review'] = reviews['processed_review'].apply(Utilities.preprocess)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print first five reviews before and after preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "display(reviews[['review', 'processed_review']].head(5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lemmatization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reviews['lem_processed_review'] = reviews['processed_review'].apply(Lemmatization.lemmatize_sent)\n",
    "\n",
    "display(reviews[['processed_review', 'lem_processed_review']].head(5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Process sentiment column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Converts categorical labels of sentiment column into binary (1 for positive, 0 for negative)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print the sentiment column unique values to confirm the encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(reviews['sentiment'].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split to train-test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = reviews['lem_processed_review'].to_numpy()\n",
    "y = reviews['sentiment_to_binary'].to_numpy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use TfidfVectorizer to transform a collection of text documents into a matrix of TF-IDF features, which reflects the importance of a term in a document relative to the entire corpus. TF-IDF adjusts the term frequencies based on how common or rare a term is across the documents.\n",
    "\n",
    "TfidfVectorizer is also a pre-processing technique used to convert text data into numerical form. TfidfVectorizer not only counts the frequency of each word but also assigns a weight to each word based on its frequency in the document and its frequency in the entire corpus. This means that it gives higher weights to words that are important or informative in the document and lower weights to common words that are not. This is achieved through a term frequency-inverse document frequency (TF-IDF) formula that balances the frequency of a word in a document with its frequency in the entire corpus.\n",
    "(https://www.kaggle.com/code/zeeshanlatif/countvectorizer-vs-tfidfvectorizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "x_train_tfidf = vectorizer.fit_transform(x_train)\n",
    "x_test_tfidf = vectorizer.transform(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def calculate_metrics(test, pred, model):\n",
    "  accuracy = accuracy_score(test, pred)\n",
    "  precision = precision_score(test, pred, average='macro')\n",
    "  recall = recall_score(test, pred, average='macro')\n",
    "  f1 = f1_score(test, pred, average='macro')\n",
    "  return [model, accuracy, precision, recall, f1]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import time\n",
    "\n",
    "average_training_time = 0\n",
    "metrics_dict = {\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1-score\": [],\n",
    "}\n",
    "\n",
    "for index in range(5):\n",
    "    random_forest = RandomForestClassifier(n_estimators=120, n_jobs=-1, criterion='gini', min_samples_split=3)\n",
    "    start_time = time.time()\n",
    "    random_forest.fit(x_train_tfidf, y_train)\n",
    "    execution_time = time.time() - start_time\n",
    "    average_training_time += execution_time\n",
    "\n",
    "    y_pred_random_forest = random_forest.predict(x_test_tfidf)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_random_forest, average='weighted')\n",
    "\n",
    "    metrics_dict[\"precision\"].append(precision)\n",
    "    metrics_dict[\"recall\"].append(recall)\n",
    "    metrics_dict[\"f1-score\"].append(f1)\n",
    "\n",
    "\n",
    "average_metrics = {metric: np.mean(values) for metric, values in metrics_dict.items()}\n",
    "\n",
    "print(\"\\n===== Average Metrics of Random forest after 5 Runs =====\")\n",
    "print(f\"Average Training Time: {average_training_time / 5:.3f} seconds\")\n",
    "print(f\"Precision: {average_metrics['precision']:.3f}\")\n",
    "print(f\"Recall: {average_metrics['recall']:.3f}\")\n",
    "print(f\"F1-Score: {average_metrics['f1-score']:.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import time\n",
    "\n",
    "average_training_time = 0\n",
    "metrics_dict = {\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1-score\": [],\n",
    "}\n",
    "\n",
    "for index in range(5):\n",
    "    naive_bayes = MultinomialNB()\n",
    "    start_time = time.time()\n",
    "    naive_bayes.fit(x_train_tfidf, y_train)\n",
    "    execution_time = time.time() - start_time\n",
    "    average_training_time += execution_time\n",
    "\n",
    "    y_predict = naive_bayes.predict(x_test_tfidf)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_random_forest, average='weighted')\n",
    "\n",
    "    metrics_dict[\"precision\"].append(precision)\n",
    "    metrics_dict[\"recall\"].append(recall)\n",
    "    metrics_dict[\"f1-score\"].append(f1)\n",
    "\n",
    "\n",
    "average_metrics = {metric: np.mean(values) for metric, values in metrics_dict.items()}\n",
    "\n",
    "print(\"\\n===== Average Metrics of Naive Bayes after 5 Runs =====\")\n",
    "print(f\"Average Training Time: {average_training_time / 5:.3f} seconds\")\n",
    "print(f\"Precision: {average_metrics['precision']:.3f}\")\n",
    "print(f\"Recall: {average_metrics['recall']:.3f}\")\n",
    "print(f\"F1-Score: {average_metrics['f1-score']:.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RNN model (Recurrent Neural Network)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Convert text data to numerical format in oreder to feed them as input to RNN model\n",
    "VOCAB_SIZE = 5000\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(x_train)  # Fit on training text\n",
    "\n",
    "# Convert text to sequences\n",
    "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# Pad sequences to ensure consistent input length\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "x_train_padded = pad_sequences(x_train_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "x_test_padded = pad_sequences(x_test_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "\n",
    "# Creating the RNN model\n",
    "model = tf.keras.Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=50),\n",
    "    Bidirectional(\n",
    "        LSTM(units=64),\n",
    "    ),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "history = model.fit(x_train_padded, y_train, validation_data=(x_test_padded, y_test), epochs=5, batch_size=64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test_padded, y_test, batch_size=64)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Get predicted probabilities\n",
    "y_probs = model.predict(x_test_padded, batch_size=64)\n",
    "\n",
    "# Convert probabilities to binary predictions (0 or 1)\n",
    "y_pred = (y_probs > 0.5).astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BERT Transformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "# Load all required metrics\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Compute f1, precision and recall metrics\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "\n",
    "    # Combine metrics into a single dictionary\n",
    "    return {\n",
    "        \"f1\": f1[\"f1\"],\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"]\n",
    "    }\n",
    "\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "model.add(tf.keras.layers.Conv1D(32, 3, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(2))\n",
    "model.add(tf.keras.layers.Conv1D(32, 3, activation='relu'))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "train_inputs = tokenizer(x_train.tolist(), padding=\"max_length\", max_length=128, truncation=True)\n",
    "\n",
    "test_inputs = tokenizer(x_test.tolist(), padding=\"max_length\", max_length=128, truncation=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert our data into tensors (https://www.analyticsvidhya.com/blog/2022/02/sentiment-analysis-using-transformers/)\n",
    "class ReviewDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = { key: torch.tensor(val[idx]) for key, val in self.encodings.items() }\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = ReviewDataset(train_inputs, y_train.tolist())\n",
    "\n",
    "test_dataset = ReviewDataset(test_inputs, y_test.tolist())\n",
    "\n",
    "print(train_dataset.__getitem__(2))\n",
    "print('\\n')\n",
    "print(test_dataset.__getitem__(2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# build the model\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=2,\n",
    "    report_to=\"none\", #remove this to save to wandb\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ROBERTA Transformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Prepare the data for transformer model (padding, truncation and all the preprocessing are done in the DistillBert tokenizer)\n",
    "tokenizer_roberta = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "train_inputs_roberta = tokenizer_roberta(x_train.tolist(), padding=\"max_length\", max_length=128, truncation=True)\n",
    "\n",
    "test_inputs_roberta = tokenizer_roberta(x_test.tolist(), padding=\"max_length\", max_length=128, truncation=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# DataCollatorWithPadding is a class in Hugging Face Transformers that helps in preparing batches of data for training transformer models\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer_roberta)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_roberta_dataset = ReviewDataset(train_inputs_roberta, y_train.tolist())\n",
    "\n",
    "test_roberta_dataset = ReviewDataset(test_inputs_roberta, y_test.tolist())\n",
    "\n",
    "print(train_roberta_dataset.__getitem__(2))\n",
    "print('\\n')\n",
    "print(test_roberta_dataset.__getitem__(2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# build the model\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\", num_labels=2, ignore_mismatched_sizes=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=2,\n",
    "    report_to=\"none\", #remove this to save to wandb\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=roberta_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_roberta_dataset,\n",
    "    eval_dataset=test_roberta_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Final example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from utils.recommendation import Recommendation\n",
    "import random\n",
    "\n",
    "value_for_positive = 'positive'\n",
    "# value_for_positive = 1\n",
    "\n",
    "def recommend_movies_based_on(movie_index):\n",
    "    movie = movies.iloc[movie_index]\n",
    "    print('Movie title: ' + movie['title'])\n",
    "\n",
    "    print('\\nSimilar movies based on plot:')\n",
    "    plot_based_similar = []\n",
    "\n",
    "    movies_with_reviews_perc=[]\n",
    "    for i in movie['similar_movie_indices']:\n",
    "        plot_based_similar.append(movies.iloc[i]['title'])\n",
    "        print(movies.iloc[i]['title'])\n",
    "\n",
    "        movie_reviews = Recommendation.get_reviews_for_movie(movies, movies.iloc[i])\n",
    "        df = pd.DataFrame(movie_reviews, columns=['review'])\n",
    "        if df['review'].size != 0:\n",
    "            df['processed_review'] = df['review'].apply(Utilities.remove_html)\n",
    "            df['processed_review'] = df['processed_review'].apply(Utilities.preprocess)\n",
    "\n",
    "            review_pred = random_forest.predict(vectorizer.transform(df['processed_review'].to_numpy()))\n",
    "            # find number of positive reviews (first column)\n",
    "             # count_of_ones = np.count_nonzero(review_pred[:, 0] == value_for_positive)\n",
    "            count_of_ones = np.sum(review_pred == 'positive')\n",
    "\n",
    "            movies_with_reviews_perc.append(tuple([movies.iloc[i]['title'], count_of_ones/df['processed_review'].size]))\n",
    "        else:\n",
    "            movies_with_reviews_perc.append(tuple([movies.iloc[i]['title'], 0]))\n",
    "\n",
    "    # Sort the list of movies by the second value (review percentage) in descending order\n",
    "    sorted_movies = sorted(movies_with_reviews_perc, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print('\\nSimilar movies based on reviews:')\n",
    "\n",
    "    top_five_pairs = sorted_movies[:5]\n",
    "\n",
    "    print([movie[0] for movie in top_five_pairs])\n",
    "    return [movie[0] for movie in top_five_pairs], plot_based_similar\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "recommended, plot = recommend_movies_based_on(random.randint(0, len(movies.axes[0])-1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
